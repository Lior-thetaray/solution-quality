{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "01212e83-3972-4d11-b68d-f1b5be71d243",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import datetime\n",
    "import dateutil.relativedelta\n",
    "\n",
    "from thetaray.api.context import init_context\n",
    "from thetaray.common import Constants\n",
    "from pyspark.sql import SQLContext\n",
    "import json\n",
    "\n",
    "from pyspark.sql import functions as f, Window, DataFrame\n",
    "from pyspark.sql.types import MapType, StringType\n",
    "\n",
    "from thetaray.api.solution import IngestionMode\n",
    "\n",
    "from thetaray.api.dataset import dataset_functions\n",
    "from thetaray.common.data_environment import DataEnvironment\n",
    "\n",
    "from common.libs.tr_levenshtein import get_lev_ind\n",
    "\n",
    "import logging\n",
    "logging.getLogger().handlers[0].setFormatter(logging.Formatter(fmt='%(levelname)s: %(asctime)s @ %(message)s',datefmt='%Y-%m-%d %H:%M:%S'))\n",
    "logging.basicConfig(level=logging.INFO)\n",
    "\n",
    "from common.libs.config.loader import load_config\n",
    "from common.libs.config.basic_execution_config_loader import BasicExecutionConfig, DevBasicExecutionConfig\n",
    "from common.libs.context_utils import is_run_triggered_from_airflow\n",
    "\n",
    "execution_date=Constants.BEGINNING_OF_TIME\n",
    "\n",
    "if is_run_triggered_from_airflow():\n",
    "    context = init_context()\n",
    "    basic_execution_config = BasicExecutionConfig(domain=context.domain,\n",
    "                                                  stage=context.parameters['stage'],\n",
    "                                                  cadence=context.parameters[\"cadence\"],\n",
    "                                                  entity=context.parameters['entity'],\n",
    "                                                  spark_conf=context.spark_conf)\n",
    "else:\n",
    "    basic_execution_config = DevBasicExecutionConfig()\n",
    "    context = init_context(execution_date=execution_date,\n",
    "                           domain=basic_execution_config.domain,\n",
    "                           spark_conf=basic_execution_config.spark_conf)\n",
    "\n",
    "print(basic_execution_config)\n",
    "spark = context.get_spark_session()\n",
    "sc = SQLContext(spark)\n",
    "params = context.parameters\n",
    "print(f\"Spark UI URL: {context.get_spark_ui_url()}\")\n",
    "\n",
    "print(json.dumps(params, indent=4))\n",
    "\n",
    "missing_values = ['', 'none', 'null']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d85fab92-bfad-40e3-a165-000ba0f611bf",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "keywords_df = dataset_functions.read(context, 'keywords')\n",
    "country_risk_df = dataset_functions.read(context, 'country_risk')\n",
    "\n",
    "print(f'keywords_df count: {keywords_df.count()}')\n",
    "print(f'country_risk_df count: {country_risk_df.count()}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c36c47ff-fba2-482a-8fa4-c658ba4f45e3",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "joined_basic_trx = dataset_functions.read(context, 'trx_basic').drop('tr_timestamp')\n",
    "trx_basic_count = joined_basic_trx.count()\n",
    "print(f'joined_basic_trx count: {trx_basic_count}')\n",
    "if trx_basic_count == 0:\n",
    "    raise Exception('trx_basic count is 0, aborting run')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cf390a38",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#Me to me\n",
    "threshold = 1\n",
    "joined_basic_trx = joined_basic_trx.withColumn(\"is_me_to_me\", get_lev_ind('creditor_name', 'debtor_name', threshold))\n",
    "print(\"Me-to-me field added\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7f38cd4c-1528-47f9-9d4e-7439e492086c",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#Keywords\n",
    "from common.libs.feature_engineering_computations_utils import enrich_trx_with_keywords\n",
    "#TODO"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "68531cfa-4e76-4da5-8309-7884f28634fd",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# TODO: Join with country_risk dataset "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2786593c-62ae-4cb3-8e23-6f6b2b29a50d",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# TODO: add additional columns"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a09224d3-ad44-43b6-8cd1-8b26bd2ab583",
   "metadata": {},
   "source": [
    "### Schema padding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c58821c0-537c-4868-864c-34489d692d4a",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from thetaray.utils.type_utils import convert_tr_type_to_spark_type\n",
    "from common.libs.context_utils import get_dataset\n",
    "trx_enriched_ds = get_dataset(context, 'trx_enriched')\n",
    "\n",
    "null_fields = [field for field in trx_enriched_ds.field_list if field.identifier not in joined_basic_trx.columns]\n",
    "for field in null_fields:\n",
    "    joined_basic_trx = joined_basic_trx.withColumn(field.identifier, f.lit(None).cast(convert_tr_type_to_spark_type(field)))\n",
    "joined_basic_trx = joined_basic_trx.select([field.identifier for field in trx_enriched_ds.field_list])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d913c06b-86b8-41ce-876f-cc24ebacc959",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "joined_basic_trx = joined_basic_trx.withColumn('year_month', f.date_trunc('month', 'delivery_timestamp'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ca383ba4-4093-4af8-b19e-eca29cfa4f80",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "joined_basic_trx.printSchema()\n",
    "print('writing trx_enriched')\n",
    "dataset_functions.write(context, joined_basic_trx, 'trx_enriched')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5d8b7b0b-e28d-4cea-b4c2-d0d734a74d07",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# print('publishing trx_enriched')\n",
    "# dataset_functions.publish(context, 'trx_enriched')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b189160d-9db0-4c5f-9fc3-78886fd96699",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "context.close()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
