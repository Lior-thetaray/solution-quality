{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "d19cebc9-333a-4fc0-9b77-f1d2c8669baf",
   "metadata": {},
   "source": [
    "### Init Context"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "040bf097-c103-4473-86e3-f50ce1face7d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from thetaray.api.context import init_context\n",
    "import datetime\n",
    "import yaml\n",
    "\n",
    "import logging\n",
    "logging.basicConfig(level=logging.DEBUG, format='%(message)s')\n",
    "\n",
    "with open('/thetaray/git/solutions/domains/demo_ret_indiv/config/spark_config.yaml') as spark_config_file:\n",
    "    spark_config = yaml.load(spark_config_file, yaml.FullLoader)['spark_config_a']\n",
    "context = init_context(execution_date=datetime.datetime(1970, 2, 1),\n",
    "                       spark_conf=spark_config,\n",
    "                       spark_master='local[*]')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "089821e6-a478-49e1-b1db-d1965dcafd88",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-06T12:45:25.256221Z",
     "iopub.status.busy": "2025-05-06T12:45:25.255592Z",
     "iopub.status.idle": "2025-05-06T12:45:25.258312Z",
     "shell.execute_reply": "2025-05-06T12:45:25.257873Z",
     "shell.execute_reply.started": "2025-05-06T12:45:25.256198Z"
    }
   },
   "source": [
    "### Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6aeaaf18-0599-4319-9d9d-1a3f396ef784",
   "metadata": {},
   "outputs": [],
   "source": [
    "from thetaray.api.dataset import dataset_functions\n",
    "\n",
    "from domains.demo_ret_indiv.datasets.customer_monthly import customer_monthly_dataset\n",
    "from domains.demo_ret_indiv.datasets.customers import customers_dataset\n",
    "from domains.demo_ret_indiv.datasets.transactions import transactions_dataset\n",
    "\n",
    "from pyspark.sql import functions as f"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "681a2b4f-d48e-45d2-9e33-e8dd29dda2c0",
   "metadata": {},
   "source": [
    "### Data Gen"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5bb54097-bb69-44b9-86bd-cfd6a6ad8a69",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import random, uuid\n",
    "from datetime import datetime\n",
    "from faker import Faker\n",
    "\n",
    "faker = Faker()\n",
    "\n",
    "# Constantes\n",
    "HIGH_RISK_COUNTRIES = ['IR', 'KP', 'SY', 'SD', 'VE', 'SO', 'YE', 'CU', 'MM', 'CF']\n",
    "STRUCTURE_THRESHOLD = 10000.0\n",
    "\n",
    "def generate_anomalous_transactions(months=12, avg_atm_per_month=15, avg_transfer_per_month=8, avg_structuring_per_month=12, avg_round_amounts_per_month=12, start_date=None):\n",
    "    \"\"\"\n",
    "    Generate synthetic transactions for the anomalous customer ANOM001 over a period of months.\n",
    "    Includes ATM withdrawals, high-risk transfers, structuring transactions, and round amounts.\n",
    "    Returns a pandas DataFrame with the full transaction schema.\n",
    "    \"\"\"\n",
    "    # Determine the starting month\n",
    "    if start_date is None:\n",
    "        today = pd.Timestamp(datetime.today().replace(day=1, hour=0, minute=0, second=0, microsecond=0))\n",
    "    else:\n",
    "        start = pd.to_datetime(start_date)\n",
    "        today = pd.Timestamp(start.replace(day=1, hour=0, minute=0, second=0, microsecond=0))\n",
    "\n",
    "    periods = [today - pd.DateOffset(months=i) for i in range(months)]\n",
    "    records = []\n",
    "    customer_id = 'ANOM001'\n",
    "    account_id = f\"ACC-{customer_id}\"\n",
    "\n",
    "    for period in periods:\n",
    "        # Number of each transaction type for this month\n",
    "        num_atm = np.random.poisson(lam=avg_atm_per_month)\n",
    "        num_transfers = np.random.poisson(lam=avg_transfer_per_month)\n",
    "        num_structures = np.random.poisson(lam=avg_structuring_per_month)\n",
    "        num_round_amounts = np.random.poisson(lam=avg_round_amounts_per_month)\n",
    "\n",
    "        # ATM transactions\n",
    "        for _ in range(num_atm):\n",
    "            trx_time = period + pd.Timedelta(days=random.randint(0,27),\n",
    "                                             hours=random.randint(0,23),\n",
    "                                             minutes=random.randint(0,59),\n",
    "                                             seconds=random.randint(0,59))\n",
    "            amt = float(np.random.randint(200, 801) * 10)  # sizeable ATM withdrawals\n",
    "            records.append({\n",
    "                'transaction_id': str(uuid.uuid4()),\n",
    "                'customer_id': customer_id,\n",
    "                'account_id': account_id,\n",
    "                'transaction_timestamp': trx_time,\n",
    "                'transaction_type_code': 'ATM',\n",
    "                'transaction_type_description': 'ATM Withdrawal',\n",
    "                'channel': 'ATM',\n",
    "                'original_trx_amount': amt,\n",
    "                'original_trx_currency': 'USD',\n",
    "                'reference_trx_amount': amt,  # assume USD reference\n",
    "                'normalized_country_amount': amt,\n",
    "                'counterparty_customer_name': None,\n",
    "                'counterparty_account': None,\n",
    "                'counterparty_contract': '',\n",
    "                'counterparty_country': None,\n",
    "                'counterparty_country_risk': None,\n",
    "                'internal': False,\n",
    "                'in_out': 'OUT',\n",
    "                'atm_id': f\"ATM-{random.randint(100,999)}\",\n",
    "                'branch_id': '',\n",
    "                'transaction_description': 'Cash withdrawal at ATM',\n",
    "                'banker_id': ''\n",
    "            })\n",
    "\n",
    "        # High-risk country transfers\n",
    "        for _ in range(num_transfers):\n",
    "            trx_time = period + pd.Timedelta(days=random.randint(0,27),\n",
    "                                             hours=random.randint(0,23),\n",
    "                                             minutes=random.randint(0,59),\n",
    "                                             seconds=random.randint(0,59))\n",
    "            country = random.choice(HIGH_RISK_COUNTRIES)\n",
    "            amt = round(float(np.random.uniform(15000, 50000)),2) # large transfer amounts\n",
    "            records.append({\n",
    "                'transaction_id': str(uuid.uuid4()),\n",
    "                'customer_id': customer_id,\n",
    "                'account_id': account_id,\n",
    "                'transaction_timestamp': trx_time,\n",
    "                'transaction_type_code': 'TRF',\n",
    "                'transaction_type_description': 'Wire Transfer',\n",
    "                'channel': 'internet',\n",
    "                'original_trx_amount': amt,\n",
    "                'original_trx_currency': 'USD',\n",
    "                'reference_trx_amount': amt,\n",
    "                'normalized_country_amount': amt,\n",
    "                'counterparty_customer_name': faker.name(),\n",
    "                'counterparty_account': f\"ACCT-{faker.bothify('????-########')}\",\n",
    "                'counterparty_contract': '',\n",
    "                'counterparty_country': country,\n",
    "                'counterparty_country_risk': 'High',\n",
    "                'internal': False,\n",
    "                'in_out': random.choice(['IN', 'OUT']),\n",
    "                'atm_id': None,\n",
    "                'branch_id': '',\n",
    "                'transaction_description': f\"Wire transfer\",\n",
    "                'banker_id': ''\n",
    "            })\n",
    "\n",
    "        # Structuring transactions (just below the reporting threshold)\n",
    "        for _ in range(num_structures):\n",
    "            trx_time = period + pd.Timedelta(days=random.randint(0,27),\n",
    "                                             hours=random.randint(0,23),\n",
    "                                             minutes=random.randint(0,59),\n",
    "                                             seconds=random.randint(0,59))\n",
    "            amt = float(round(STRUCTURE_THRESHOLD - np.random.uniform(1, 50), 0))\n",
    "            # random choice of channel\n",
    "            channel = random.choice(['TELLER', 'ATM'])\n",
    "            records.append({\n",
    "                'transaction_id': str(uuid.uuid4()),\n",
    "                'customer_id': customer_id,\n",
    "                'account_id': account_id,\n",
    "                'transaction_timestamp': trx_time,\n",
    "                'transaction_type_code': 'STRUCTURING',\n",
    "                'transaction_type_description': 'Structuring',\n",
    "                'channel': channel,\n",
    "                'original_trx_amount': amt,\n",
    "                'original_trx_currency': 'USD',\n",
    "                'reference_trx_amount': amt,\n",
    "                'normalized_country_amount': amt,\n",
    "                'counterparty_customer_name': None,\n",
    "                'counterparty_account': None,\n",
    "                'counterparty_contract': '',\n",
    "                'counterparty_country': None,\n",
    "                'counterparty_country_risk': None,\n",
    "                'internal': False,\n",
    "                'in_out': 'IN',\n",
    "                'atm_id': f\"ATM-{random.randint(100,999)}\" if channel == 'ATM' else None,\n",
    "                'branch_id': '',\n",
    "                'transaction_description': 'Cash deposit',\n",
    "                'banker_id': ''\n",
    "            })\n",
    "\n",
    "        # Round amount transactions\n",
    "        for _ in range(num_round_amounts):\n",
    "            trx_time = period + pd.Timedelta(days=random.randint(0,27),\n",
    "                                             hours=random.randint(0,23),\n",
    "                                             minutes=random.randint(0,59),\n",
    "                                             seconds=random.randint(0,59))\n",
    "            amt = float(np.random.randint(1,10)*1000)  # Asegurar que sean múltiplos de 10\n",
    "            # random choice of channel\n",
    "            channel = random.choice(['TELLER', 'ATM'])\n",
    "            records.append({\n",
    "                'transaction_id': str(uuid.uuid4()),\n",
    "                'customer_id': customer_id,\n",
    "                'account_id': account_id,\n",
    "                'transaction_timestamp': trx_time,\n",
    "                'transaction_type_code': 'ROUND_AMOUNT',\n",
    "                'transaction_type_description': 'Round Amount',\n",
    "                'channel': channel,\n",
    "                'original_trx_amount': amt,\n",
    "                'original_trx_currency': 'USD',\n",
    "                'reference_trx_amount': amt,\n",
    "                'normalized_country_amount': amt,\n",
    "                'counterparty_customer_name': None,\n",
    "                'counterparty_account': None,\n",
    "                'counterparty_contract': '',\n",
    "                'counterparty_country': None,\n",
    "                'counterparty_country_risk': None,\n",
    "                'internal': False,\n",
    "                'in_out': np.random.choice(['IN','OUT']),\n",
    "                'atm_id': f\"ATM-{random.randint(100,999)}\" if channel == 'ATM' else None,\n",
    "                'branch_id': '',\n",
    "                'transaction_description': 'Round amount transaction',\n",
    "                'banker_id': ''\n",
    "            })\n",
    "\n",
    "    df = pd.DataFrame(records)\n",
    "    # Ensure correct ordering\n",
    "    df.sort_values('transaction_timestamp', inplace=True)\n",
    "    df.reset_index(drop=True, inplace=True)\n",
    "    return df\n",
    "\n",
    "def calculate_aggregated_features_from_transactions(df_trx, customer_id, customer_name):\n",
    "    \"\"\"\n",
    "    Calcula las features agregadas mes-a-mes a partir de las transacciones reales generadas.\n",
    "    NO randomiza los resultados, sino que los calcula desde los datos reales.\n",
    "    \"\"\"\n",
    "    if df_trx.empty:\n",
    "        return pd.DataFrame()\n",
    "    \n",
    "    # 1) Extrae la columna year_month como timestamp al primer día del mes\n",
    "    df_trx = df_trx.copy()\n",
    "    df_trx['year_month'] = df_trx['transaction_timestamp'].dt.to_period('M').dt.to_timestamp()\n",
    "    \n",
    "    # 2) Calcula las métricas reales basándose en los datos:\n",
    "    \n",
    "    results = []\n",
    "    \n",
    "    for period, group in df_trx.groupby('year_month'):\n",
    "        # Structuring: suma de montos de transacciones tipo STRUCTURING\n",
    "        structuring_txs = group[group['transaction_type_code'] == 'STRUCTURING']\n",
    "        structuring = float(structuring_txs['original_trx_amount'].sum())\n",
    "        \n",
    "        # Count distinct ATM: número de transacciones ATM\n",
    "        cnt_distinct_atm = int((group['transaction_type_code'] == 'ATM').sum())\n",
    "        \n",
    "        # Sum high-risk transfers: suma de montos de transferencias a países de alto riesgo\n",
    "        high_risk_txs = group[group['transaction_type_code'] == 'TRF']\n",
    "        sum_trx_high_risk = float(high_risk_txs['original_trx_amount'].sum())\n",
    "        \n",
    "        # Round amounts: número de transacciones con montos redondos\n",
    "        round_amounts_txs = group[group['transaction_type_code'] == 'ROUND_AMOUNT']\n",
    "        round_amounts = int(len(round_amounts_txs))\n",
    "        \n",
    "        # Detectar deposit-withdrawal pipe: alternar IN/OUT en cortos períodos\n",
    "        # Ordenar por timestamp y detectar patrones alternantes\n",
    "        group_sorted = group.sort_values('transaction_timestamp')\n",
    "        pipe_score = 0.0\n",
    "        if len(group_sorted) > 1:\n",
    "            in_out_sequence = group_sorted['in_out'].tolist()\n",
    "            alternating_count = 0\n",
    "            for i in range(1, len(in_out_sequence)):\n",
    "                if in_out_sequence[i] != in_out_sequence[i-1]:\n",
    "                    alternating_count += 1\n",
    "            # Ratio de alternancia como indicador de pipe behavior\n",
    "            pipe_score = alternating_count / max(1, len(in_out_sequence) - 1)\n",
    "        \n",
    "        # Overall activity spike: detectar picos de actividad\n",
    "        # Contar transacciones por día y detectar días con actividad inusual\n",
    "        daily_counts = group.groupby(group['transaction_timestamp'].dt.date).size()\n",
    "        activity_spike = 0\n",
    "        if len(daily_counts) > 0:\n",
    "            threshold = daily_counts.mean() + 2 * daily_counts.std()\n",
    "            activity_spike = int((daily_counts > threshold).sum())\n",
    "        \n",
    "        # Calcular pop factors basados en volúmenes reales\n",
    "        pop_factor = random.uniform(0.002, 0.006)  # Factor poblacional para cliente anómalo\n",
    "        \n",
    "        results.append({\n",
    "            'customer_id': customer_id,\n",
    "            'customer_name': customer_name,\n",
    "            'year_month': period,\n",
    "            'year_month_str': period.strftime('%Y-%m'),\n",
    "            'structuring': structuring,\n",
    "            'cnt_distinct_atm': cnt_distinct_atm,\n",
    "            'cnt_distinct_atm_pop': cnt_distinct_atm * pop_factor,\n",
    "            'sum_trx_high_risk': sum_trx_high_risk,\n",
    "            'sum_trx_high_risk_pop': sum_trx_high_risk * pop_factor,\n",
    "            'deposit_withdrawal_pipe': pipe_score,\n",
    "            'overall_activity_spike': float(activity_spike),\n",
    "            'crypto_activity': 0.0,  # No hay crypto en este dataset\n",
    "            'check_deposit_value': 0.0,  # No hay cheques en este dataset\n",
    "            'round_amounts': float(round_amounts)\n",
    "        })\n",
    "    \n",
    "    return pd.DataFrame(results)\n",
    "\n",
    "def generate_normal_individual_transactions(customer_id, customer_name, period, n_transactions=20):\n",
    "    \"\"\"\n",
    "    Genera transacciones normales para clientes individuales regulares\n",
    "    \"\"\"\n",
    "    records = []\n",
    "    account_id = f\"ACC-{customer_id}\"\n",
    "    \n",
    "    # Generar transacciones distribuidas a lo largo del mes\n",
    "    for _ in range(n_transactions):\n",
    "        ts = period + pd.Timedelta(\n",
    "            days=random.randint(0, 27),\n",
    "            hours=random.randint(0, 23),\n",
    "            minutes=random.randint(0, 59),\n",
    "            seconds=random.randint(0, 59)\n",
    "        )\n",
    "        \n",
    "        # Tipos de transacciones normales\n",
    "        tx_type = random.choice(['ATM', 'TRANSFER', 'DEPOSIT', 'PURCHASE'])\n",
    "        channel = random.choice(['ATM', 'internet', 'branch', 'mobile'])\n",
    "        \n",
    "        # Montos normales (más pequeños que el cliente anómalo)\n",
    "        if tx_type == 'ATM':\n",
    "            amt = float(np.random.randint(20, 100) * 10)  # ATM normales más pequeños\n",
    "        elif tx_type == 'TRANSFER':\n",
    "            amt = round(float(np.random.uniform(500, 5000)), 2)  # Transferencias normales\n",
    "        else:\n",
    "            amt = round(float(np.random.uniform(100, 2000)), 2)  # Otros tipos\n",
    "        \n",
    "        # Países de bajo riesgo para transferencias\n",
    "        if tx_type == 'TRANSFER':\n",
    "            country = random.choice(['CA', 'GB', 'FR', 'DE', 'AU', 'JP'])\n",
    "            country_risk = 'Low'\n",
    "        else:\n",
    "            country = None\n",
    "            country_risk = None\n",
    "        \n",
    "        records.append({\n",
    "            'transaction_id': str(uuid.uuid4()),\n",
    "            'customer_id': customer_id,\n",
    "            'customer_name': customer_name,\n",
    "            'account_id': account_id,\n",
    "            'transaction_timestamp': ts,\n",
    "            'transaction_type_code': tx_type,\n",
    "            'transaction_type_description': f'{tx_type} Transaction',\n",
    "            'channel': channel,\n",
    "            'original_trx_amount': amt,\n",
    "            'original_trx_currency': 'USD',\n",
    "            'reference_trx_amount': amt,\n",
    "            'normalized_country_amount': amt,\n",
    "            'counterparty_customer_name': faker.name() if tx_type == 'TRANSFER' else None,\n",
    "            'counterparty_account': f\"ACCT-{faker.bothify('????-########')}\" if tx_type == 'TRANSFER' else None,\n",
    "            'counterparty_contract': '',\n",
    "            'counterparty_country': country,\n",
    "            'counterparty_country_risk': country_risk,\n",
    "            'internal': False,\n",
    "            'in_out': random.choice(['IN', 'OUT']),\n",
    "            'atm_id': f\"ATM-{random.randint(100,999)}\" if channel == 'ATM' else None,\n",
    "            'branch_id': f\"BR-{random.randint(100,999)}\" if channel == 'branch' else '',\n",
    "            'transaction_description': f'Normal {tx_type.lower()} transaction',\n",
    "            'banker_id': f\"BNK-{random.randint(1000,9999)}\" if channel == 'branch' else ''\n",
    "        })\n",
    "    \n",
    "    return records\n",
    "\n",
    "def calculate_normal_aggregated_features(transactions_df, customer_id, customer_name, period):\n",
    "    \"\"\"\n",
    "    Calcula features agregadas para clientes normales basándose en sus transacciones reales\n",
    "    \"\"\"\n",
    "    # Filtrar transacciones del período mensual específico\n",
    "    start_date = period\n",
    "    end_date = period + pd.DateOffset(months=1)\n",
    "    mask = (transactions_df['transaction_timestamp'] >= start_date) & \\\n",
    "           (transactions_df['transaction_timestamp'] < end_date) & \\\n",
    "           (transactions_df['customer_id'] == customer_id)\n",
    "    \n",
    "    period_txs = transactions_df[mask].copy()\n",
    "    \n",
    "    if len(period_txs) == 0:\n",
    "        # Si no hay transacciones, devolver valores por defecto\n",
    "        return {\n",
    "            'customer_id': customer_id,\n",
    "            'customer_name': customer_name,\n",
    "            'year_month': period,\n",
    "            'year_month_str': period.strftime(\"%Y-%m\"),\n",
    "            'structuring': 0.0,\n",
    "            'cnt_distinct_atm': 0.0,\n",
    "            'cnt_distinct_atm_pop': 0.0,\n",
    "            'sum_trx_high_risk': 0.0,\n",
    "            'sum_trx_high_risk_pop': 0.0,\n",
    "            'deposit_withdrawal_pipe': 0.0,\n",
    "            'overall_activity_spike': 0.0,\n",
    "            'crypto_activity': 0.0,\n",
    "            'check_deposit_value': 0.0,\n",
    "            'round_amounts': 0.0\n",
    "        }\n",
    "    \n",
    "    # Calcular métricas basándose en transacciones reales\n",
    "    # Structuring: para clientes normales será 0 o muy bajo\n",
    "    structuring_txs = period_txs[period_txs['transaction_type_code'] == 'STRUCTURING']\n",
    "    structuring = float(structuring_txs['original_trx_amount'].sum())\n",
    "    \n",
    "    # ATM count\n",
    "    cnt_distinct_atm = float(int((period_txs['transaction_type_code'] == 'ATM').sum()))\n",
    "    \n",
    "    # High-risk transfers: clientes normales tienen pocos o ninguno\n",
    "    high_risk_txs = period_txs[\n",
    "        (period_txs['transaction_type_code'] == 'TRANSFER') & \n",
    "        (period_txs['counterparty_country'].isin(HIGH_RISK_COUNTRIES))\n",
    "    ]\n",
    "    sum_trx_high_risk = float(high_risk_txs['original_trx_amount'].sum())\n",
    "    \n",
    "    # Round amounts\n",
    "    round_amounts_txs = period_txs[period_txs['transaction_type_code'] == 'ROUND_AMOUNT']\n",
    "    round_amounts = float(len(round_amounts_txs))\n",
    "    \n",
    "    # Pipe behavior (más bajo para clientes normales)\n",
    "    pipe_score = 0.0\n",
    "    if len(period_txs) > 1:\n",
    "        period_txs_sorted = period_txs.sort_values('transaction_timestamp')\n",
    "        in_out_sequence = period_txs_sorted['in_out'].tolist()\n",
    "        alternating_count = 0\n",
    "        for i in range(1, len(in_out_sequence)):\n",
    "            if in_out_sequence[i] != in_out_sequence[i-1]:\n",
    "                alternating_count += 1\n",
    "        pipe_score = alternating_count / max(1, len(in_out_sequence) - 1)\n",
    "    \n",
    "    # Activity spike (menor para clientes normales)\n",
    "    daily_counts = period_txs.groupby(period_txs['transaction_timestamp'].dt.date).size()\n",
    "    activity_spike = 0\n",
    "    if len(daily_counts) > 0:\n",
    "        threshold = daily_counts.mean() + 2 * daily_counts.std()\n",
    "        activity_spike = int((daily_counts > threshold).sum())\n",
    "    \n",
    "    # Pop factors para clientes normales (menores)\n",
    "    pop_factor = random.uniform(0.001, 0.002)\n",
    "    \n",
    "    return {\n",
    "        'customer_id': customer_id,\n",
    "        'customer_name': customer_name,\n",
    "        'year_month': period,\n",
    "        'year_month_str': period.strftime(\"%Y-%m\"),\n",
    "        'structuring': structuring,\n",
    "        'cnt_distinct_atm': cnt_distinct_atm,\n",
    "        'cnt_distinct_atm_pop': cnt_distinct_atm * pop_factor,\n",
    "        'sum_trx_high_risk': sum_trx_high_risk,\n",
    "        'sum_trx_high_risk_pop': sum_trx_high_risk * pop_factor,\n",
    "        'deposit_withdrawal_pipe': pipe_score,\n",
    "        'overall_activity_spike': float(activity_spike),\n",
    "        'crypto_activity': 0.0,\n",
    "        'check_deposit_value': 0.0,\n",
    "        'round_amounts': round_amounts\n",
    "    }\n",
    "\n",
    "def generate_aggregated_dataset(n_customers=100, months=12, transactions_per_customer_per_month=20):\n",
    "    \"\"\"\n",
    "    Genera el dataset completo de individuos: transacciones + features agregadas\n",
    "    \"\"\"\n",
    "    # Preparar clientes\n",
    "    normal_customers = [f\"IND{i:04d}\" for i in range(n_customers - 1)]\n",
    "    anomaly_customer = \"ANOM001\"\n",
    "    all_customers = normal_customers + [anomaly_customer]\n",
    "    \n",
    "    # Generar nombres\n",
    "    customer_names = {cust: faker.name() for cust in all_customers}\n",
    "    \n",
    "    # Preparar períodos\n",
    "    today = pd.Timestamp(datetime.today().replace(day=1, hour=0, minute=0, second=0, microsecond=0))\n",
    "    periods = [today - pd.DateOffset(months=i) for i in range(months)]\n",
    "    \n",
    "    # 1. Generar todas las transacciones\n",
    "    all_transactions = []\n",
    "    \n",
    "    # Transacciones para clientes normales\n",
    "    for customer in normal_customers:\n",
    "        for period in periods:\n",
    "            txs = generate_normal_individual_transactions(\n",
    "                customer_id=customer,\n",
    "                customer_name=customer_names[customer],\n",
    "                period=period,\n",
    "                n_transactions=transactions_per_customer_per_month\n",
    "            )\n",
    "            all_transactions.extend(txs)\n",
    "    \n",
    "    # Transacciones para cliente anómalo\n",
    "    anomaly_txs = generate_anomalous_transactions(months=months)\n",
    "    all_transactions.extend(anomaly_txs.to_dict('records'))\n",
    "    \n",
    "    # Convertir a DataFrame\n",
    "    transactions_df = pd.DataFrame(all_transactions)\n",
    "    \n",
    "    # 2. Calcular features agregadas\n",
    "    aggregated_records = []\n",
    "    \n",
    "    # Features para clientes normales\n",
    "    for customer in normal_customers:\n",
    "        for period in periods:\n",
    "            features = calculate_normal_aggregated_features(\n",
    "                transactions_df=transactions_df,\n",
    "                customer_id=customer,\n",
    "                customer_name=customer_names[customer],\n",
    "                period=period\n",
    "            )\n",
    "            aggregated_records.append(features)\n",
    "    \n",
    "    # Features para cliente anómalo (calculadas desde transacciones reales)\n",
    "    anomaly_features = calculate_aggregated_features_from_transactions(\n",
    "        df_trx=anomaly_txs,\n",
    "        customer_id=anomaly_customer,\n",
    "        customer_name=customer_names[anomaly_customer]\n",
    "    )\n",
    "    aggregated_records.extend(anomaly_features.to_dict('records'))\n",
    "    \n",
    "    aggregated_df = pd.DataFrame(aggregated_records)\n",
    "    \n",
    "    # Ordenar datasets\n",
    "    transactions_df = transactions_df.sort_values(['customer_id', 'transaction_timestamp'])\n",
    "    aggregated_df = aggregated_df.sort_values(['customer_id', 'year_month'])\n",
    "    \n",
    "    return transactions_df, aggregated_df\n",
    "\n",
    "def generate_anomalous_kyc(name):\n",
    "    \"\"\"\n",
    "    Generate KYC record for the anomalous customer.\n",
    "    Returns a pandas DataFrame with one record.\n",
    "    \"\"\"\n",
    "    dob = faker.date_of_birth(minimum_age=30, maximum_age=70)\n",
    "    eff_date = faker.date_between(start_date='-5y', end_date='-1y')\n",
    "    data = {\n",
    "        'customer_id': 'ANOM001',\n",
    "        'customer_num': f\"NUM-{faker.bothify('######')}\",\n",
    "        'type_of_document': random.choice(['Passport', 'Driver License', 'National ID']),\n",
    "        'document_number_id_code': faker.bothify('??########'),\n",
    "        'name': name,\n",
    "        'date_of_birth': dob,\n",
    "        'country_of_birth_nationality': 'CU',\n",
    "        'tax_residency_countries': 'United States',\n",
    "        'country_of_residence_code': 'US',\n",
    "        'country_of_residence': 'United States',\n",
    "        'citizenship_countries_code': 'US',\n",
    "        'citizenship_countries': 'United States, Cuba',\n",
    "        'address': faker.address(),\n",
    "        'phone_number': faker.phone_number(),\n",
    "        'occupation': random.choice(['Entrepreneur', 'Investor', 'Consultant', 'Executive']),\n",
    "        'is_unemployed': False,\n",
    "        'customer_effective_date': eff_date,\n",
    "        'aml_risk_segment': random.randint(4,6),\n",
    "        'pep': random.choice([True, False]),\n",
    "        'segment_type': 'PERS',\n",
    "        'segment_type_description': 'Personal',\n",
    "        'sars_flag': False\n",
    "    }\n",
    "    return pd.DataFrame([data])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7f2de590-92ee-496c-9c4f-57cbc6aa0bfa",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_trx, agg_df = generate_aggregated_dataset()\n",
    "dataset_functions.write(context, context.get_spark_session().createDataFrame(agg_df), customer_monthly_dataset().identifier)\n",
    "anom_name = agg_df.loc[agg_df.customer_id=='ANOM001']['customer_name'].iloc[0]\n",
    "\n",
    "dataset_functions.write(\n",
    "    context,\n",
    "    context.get_spark_session().createDataFrame(df_trx),\n",
    "    transactions_dataset().identifier\n",
    ")\n",
    "dataset_functions.publish(context, transactions_dataset().identifier)\n",
    "\n",
    "dataset_functions.write(context, context.get_spark_session().createDataFrame(generate_anomalous_kyc(name=anom_name)), customers_dataset().identifier)\n",
    "dataset_functions.publish(context, customers_dataset().identifier)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a8ff4a06-1fec-4f21-a60d-b758a671794b",
   "metadata": {},
   "outputs": [],
   "source": [
    "context.close()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.20"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
