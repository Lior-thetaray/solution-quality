{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import datetime\n",
    "import mlflow\n",
    "\n",
    "from thetaray.api.evaluation.preprocess.numeric_features import NumericFeaturesTransformer\n",
    "from thetaray.api.evaluation.preprocess.features_extractor import FeaturesExtractor\n",
    "from thetaray.api.evaluation.preprocess.categorical_features import CategoricalFeaturesTransformer\n",
    "from thetaray.api.context import init_context\n",
    "from thetaray.api.sample import get_sample_percent_unlabeled\n",
    "from thetaray.api.evaluation import fit_on_worker\n",
    "from thetaray.api.models import save_model\n",
    "from thetaray.api.dataset import dataset_functions\n",
    "from thetaray.api.anomaly_detection import ThetaRayDetector\n",
    "from thetaray.api.metric import CustomMetricPublisher\n",
    "from thetaray.api.histograms import save_histograms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": [
     "parameters"
    ]
   },
   "outputs": [],
   "source": [
    "from thetaray.api.solution import EvaluationType"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "context = init_context(execution_date=datetime.datetime(1970,1,1))\n",
    "spark = context.get_spark_session()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = dataset_functions.read(context, 'wrangling', generate_pk=True)\n",
    "data = data.replace(float('nan'), None)\n",
    "data = data.drop('tr_timestamp')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sample = get_sample_percent_unlabeled(data, 20)\n",
    "sample_pd = sample.toPandas()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = sample_pd.drop(columns=['tr_pk'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "features_list = ['amount',\n",
    "'duration',\n",
    "'payments',\n",
    "'birth_number',\n",
    "'min1',\n",
    "'max1',\n",
    "'mean1',\n",
    "'min2',\n",
    "'max2',\n",
    "'mean2',\n",
    "'min3',\n",
    "'max3',\n",
    "'mean3',\n",
    "'min4',\n",
    "'max4',\n",
    "'mean4',\n",
    "'min5',\n",
    "'max5',\n",
    "'mean5',\n",
    "'min6',\n",
    "'max6',\n",
    "'mean6',\n",
    "'has_card']\n",
    "nft = NumericFeaturesTransformer(features=features_list,strategy='mean',fill_value=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fu = FeaturesExtractor([\n",
    "    nft,\n",
    "    CategoricalFeaturesTransformer(features=['frequency', 'type_disp', 'type_card'], mapping=None, strategy=None, fill_value=None)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with mlflow.start_run(nested=True):\n",
    "    CustomMetricPublisher(\n",
    "        execution_date=context.execution_date, metric_type='tr_algo_train', publish_to_mlflow=True, publish_to_es=True\n",
    "    ).log_param('model_type', EvaluationType.THETARAY_ANALYSIS)\n",
    "    feature_extraction_model = fit_on_worker(fu.fit, X=X)\n",
    "    save_model('tr_feature_extraction_model', feature_extraction_model, tags={\"version\": \"release\"})\n",
    "    detection_model, captured_stdout, captured_stderr = fit_on_worker(ThetaRayDetector(algo_type=['GC'], Fusion_threshold=0.45).fit, X=feature_extraction_model.transform(X), capture_stdout=True)\n",
    "    save_model('tr_detection_model', detection_model, tags={\"version\": \"release\"})\n",
    "    save_histograms(context, sample, features_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# Workaround to finish spark job, as spark-joblib uses pyspark API with bugs (will be fixed in spark 3)\n",
    "spark.stop()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
