{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "d19cebc9-333a-4fc0-9b77-f1d2c8669baf",
   "metadata": {},
   "source": [
    "### Init Context"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "040bf097-c103-4473-86e3-f50ce1face7d",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-07-19T14:17:48.547404Z",
     "iopub.status.busy": "2025-07-19T14:17:48.547188Z",
     "iopub.status.idle": "2025-07-19T14:18:27.659931Z",
     "shell.execute_reply": "2025-07-19T14:18:27.659098Z",
     "shell.execute_reply.started": "2025-07-19T14:17:48.547385Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-07-19 14:17:59,017:INFO:thetaray.common.logging:start loading solution.....[ load_risks=True , solution_path=/thetaray/git/solutions/domains , settings_path=/thetaray/git/solutions/settings ]\n",
      "2025-07-19 14:17:59,023:WARNING:thetaray.common.logging:Encryption is enabled on dataset demo_remittance_customer_insights, but data encryption is disabled in deployment\n",
      "2025-07-19 14:17:59,032:WARNING:thetaray.common.logging:Encryption is enabled on dataset demo_ret_smb_customer_insights, but data encryption is disabled in deployment\n",
      "2025-07-19 14:17:59,055:WARNING:thetaray.common.logging:Encryption is enabled on dataset wrangling, but data encryption is disabled in deployment\n",
      "2025-07-19 14:17:59,057:WARNING:thetaray.common.logging:Encryption is enabled on dataset party_wrangling, but data encryption is disabled in deployment\n",
      "2025-07-19 14:17:59,058:WARNING:thetaray.common.logging:Encryption is enabled on dataset customer_insights, but data encryption is disabled in deployment\n",
      "2025-07-19 14:17:59,059:WARNING:thetaray.common.logging:Encryption is enabled on dataset transaction, but data encryption is disabled in deployment\n",
      "2025-07-19 14:17:59,059:WARNING:thetaray.common.logging:Encryption is enabled on dataset account, but data encryption is disabled in deployment\n",
      "2025-07-19 14:17:59,061:WARNING:thetaray.common.logging:Encryption is enabled on dataset demo_pay_proc_customer_insights, but data encryption is disabled in deployment\n",
      "2025-07-19 14:17:59,067:WARNING:thetaray.common.logging:Encryption is enabled on dataset demo_ret_indiv_customer_insights, but data encryption is disabled in deployment\n",
      "2025-07-19 14:17:59,141:WARNING:thetaray.common.logging:Property AN is configured as encrypted, but data encryption is disabled\n",
      "2025-07-19 14:17:59,141:WARNING:thetaray.common.logging:Property NM is configured as encrypted, but data encryption is disabled\n",
      "2025-07-19 14:17:59,141:WARNING:thetaray.common.logging:Property CT is configured as encrypted, but data encryption is disabled\n",
      "2025-07-19 14:17:59,141:WARNING:thetaray.common.logging:Property AD is configured as encrypted, but data encryption is disabled\n",
      "2025-07-19 14:17:59,141:WARNING:thetaray.common.logging:Node AC is configured as encrypted, but data encryption is disabled\n",
      "2025-07-19 14:17:59,141:WARNING:thetaray.common.logging:Property PI is configured as encrypted, but data encryption is disabled\n",
      "2025-07-19 14:17:59,141:WARNING:thetaray.common.logging:Property NM is configured as encrypted, but data encryption is disabled\n",
      "2025-07-19 14:17:59,141:WARNING:thetaray.common.logging:Property AD is configured as encrypted, but data encryption is disabled\n",
      "2025-07-19 14:17:59,141:WARNING:thetaray.common.logging:Property CT is configured as encrypted, but data encryption is disabled\n",
      "2025-07-19 14:17:59,141:WARNING:thetaray.common.logging:Node PR is configured as encrypted, but data encryption is disabled\n",
      "2025-07-19 14:17:59,141:WARNING:thetaray.common.logging:Edge ER is configured as encrypted, but data encryption is disabled\n",
      "2025-07-19 14:17:59,141:WARNING:thetaray.common.logging:Edge ER is configured as encrypted, but data encryption is disabled\n",
      "2025-07-19 14:17:59,142:WARNING:thetaray.common.logging:Property AN is configured as encrypted, but data encryption is disabled\n",
      "2025-07-19 14:17:59,142:WARNING:thetaray.common.logging:Property NM is configured as encrypted, but data encryption is disabled\n",
      "2025-07-19 14:17:59,142:WARNING:thetaray.common.logging:Property CT is configured as encrypted, but data encryption is disabled\n",
      "2025-07-19 14:17:59,142:WARNING:thetaray.common.logging:Property AD is configured as encrypted, but data encryption is disabled\n",
      "2025-07-19 14:17:59,142:WARNING:thetaray.common.logging:Node AC is configured as encrypted, but data encryption is disabled\n",
      "2025-07-19 14:17:59,142:WARNING:thetaray.common.logging:Property PI is configured as encrypted, but data encryption is disabled\n",
      "2025-07-19 14:17:59,142:WARNING:thetaray.common.logging:Property NM is configured as encrypted, but data encryption is disabled\n",
      "2025-07-19 14:17:59,142:WARNING:thetaray.common.logging:Property AD is configured as encrypted, but data encryption is disabled\n",
      "2025-07-19 14:17:59,142:WARNING:thetaray.common.logging:Property CT is configured as encrypted, but data encryption is disabled\n",
      "2025-07-19 14:17:59,142:WARNING:thetaray.common.logging:Node PR is configured as encrypted, but data encryption is disabled\n",
      "2025-07-19 14:17:59,142:WARNING:thetaray.common.logging:Edge ER is configured as encrypted, but data encryption is disabled\n",
      "2025-07-19 14:17:59,142:WARNING:thetaray.common.logging:Edge ER is configured as encrypted, but data encryption is disabled\n",
      "2025-07-19 14:17:59,143:WARNING:thetaray.common.logging:Property AN is configured as encrypted, but data encryption is disabled\n",
      "2025-07-19 14:17:59,143:WARNING:thetaray.common.logging:Property NM is configured as encrypted, but data encryption is disabled\n",
      "2025-07-19 14:17:59,143:WARNING:thetaray.common.logging:Property CT is configured as encrypted, but data encryption is disabled\n",
      "2025-07-19 14:17:59,143:WARNING:thetaray.common.logging:Property AD is configured as encrypted, but data encryption is disabled\n",
      "2025-07-19 14:17:59,143:WARNING:thetaray.common.logging:Node AC is configured as encrypted, but data encryption is disabled\n",
      "2025-07-19 14:17:59,143:WARNING:thetaray.common.logging:Property PI is configured as encrypted, but data encryption is disabled\n",
      "2025-07-19 14:17:59,143:WARNING:thetaray.common.logging:Property NM is configured as encrypted, but data encryption is disabled\n",
      "2025-07-19 14:17:59,143:WARNING:thetaray.common.logging:Property AD is configured as encrypted, but data encryption is disabled\n",
      "2025-07-19 14:17:59,143:WARNING:thetaray.common.logging:Property CT is configured as encrypted, but data encryption is disabled\n",
      "2025-07-19 14:17:59,143:WARNING:thetaray.common.logging:Node PR is configured as encrypted, but data encryption is disabled\n",
      "2025-07-19 14:17:59,143:WARNING:thetaray.common.logging:Edge ER is configured as encrypted, but data encryption is disabled\n",
      "2025-07-19 14:17:59,143:WARNING:thetaray.common.logging:Edge ER is configured as encrypted, but data encryption is disabled\n",
      "2025-07-19 14:17:59,143:WARNING:thetaray.common.logging:Property AN is configured as encrypted, but data encryption is disabled\n",
      "2025-07-19 14:17:59,143:WARNING:thetaray.common.logging:Property NM is configured as encrypted, but data encryption is disabled\n",
      "2025-07-19 14:17:59,143:WARNING:thetaray.common.logging:Property CT is configured as encrypted, but data encryption is disabled\n",
      "2025-07-19 14:17:59,143:WARNING:thetaray.common.logging:Property AD is configured as encrypted, but data encryption is disabled\n",
      "2025-07-19 14:17:59,143:WARNING:thetaray.common.logging:Node AC is configured as encrypted, but data encryption is disabled\n",
      "2025-07-19 14:17:59,144:WARNING:thetaray.common.logging:Property PI is configured as encrypted, but data encryption is disabled\n",
      "2025-07-19 14:17:59,144:WARNING:thetaray.common.logging:Property NM is configured as encrypted, but data encryption is disabled\n",
      "2025-07-19 14:17:59,144:WARNING:thetaray.common.logging:Property AD is configured as encrypted, but data encryption is disabled\n",
      "2025-07-19 14:17:59,144:WARNING:thetaray.common.logging:Property CT is configured as encrypted, but data encryption is disabled\n",
      "2025-07-19 14:17:59,144:WARNING:thetaray.common.logging:Node PR is configured as encrypted, but data encryption is disabled\n",
      "2025-07-19 14:17:59,144:WARNING:thetaray.common.logging:Edge ER is configured as encrypted, but data encryption is disabled\n",
      "2025-07-19 14:17:59,144:WARNING:thetaray.common.logging:Edge ER is configured as encrypted, but data encryption is disabled\n",
      "2025-07-19 14:17:59,144:WARNING:thetaray.common.logging:Property AN is configured as encrypted, but data encryption is disabled\n",
      "2025-07-19 14:17:59,144:WARNING:thetaray.common.logging:Property NM is configured as encrypted, but data encryption is disabled\n",
      "2025-07-19 14:17:59,144:WARNING:thetaray.common.logging:Property CT is configured as encrypted, but data encryption is disabled\n",
      "2025-07-19 14:17:59,144:WARNING:thetaray.common.logging:Property AD is configured as encrypted, but data encryption is disabled\n",
      "2025-07-19 14:17:59,144:WARNING:thetaray.common.logging:Node AC is configured as encrypted, but data encryption is disabled\n",
      "2025-07-19 14:17:59,144:WARNING:thetaray.common.logging:Property PI is configured as encrypted, but data encryption is disabled\n",
      "2025-07-19 14:17:59,144:WARNING:thetaray.common.logging:Property NM is configured as encrypted, but data encryption is disabled\n",
      "2025-07-19 14:17:59,144:WARNING:thetaray.common.logging:Property AD is configured as encrypted, but data encryption is disabled\n",
      "2025-07-19 14:17:59,145:WARNING:thetaray.common.logging:Property CT is configured as encrypted, but data encryption is disabled\n",
      "2025-07-19 14:17:59,145:WARNING:thetaray.common.logging:Node PR is configured as encrypted, but data encryption is disabled\n",
      "2025-07-19 14:17:59,145:WARNING:thetaray.common.logging:Edge ER is configured as encrypted, but data encryption is disabled\n",
      "2025-07-19 14:17:59,145:WARNING:thetaray.common.logging:Edge ER is configured as encrypted, but data encryption is disabled\n",
      "2025-07-19 14:17:59,234:INFO:thetaray.common.logging:load_risks took: 0.08745241165161133\n",
      "2025-07-19 14:17:59,304:WARNING:thetaray.common.logging:Encryption is enabled on dataset demo_remittance_customer_insights, but data encryption is disabled in deployment\n",
      "2025-07-19 14:17:59,304:WARNING:thetaray.common.logging:Encryption is enabled on dataset demo_ret_smb_customer_insights, but data encryption is disabled in deployment\n",
      "2025-07-19 14:17:59,304:WARNING:thetaray.common.logging:Encryption is enabled on dataset wrangling, but data encryption is disabled in deployment\n",
      "2025-07-19 14:17:59,304:WARNING:thetaray.common.logging:Encryption is enabled on dataset party_wrangling, but data encryption is disabled in deployment\n",
      "2025-07-19 14:17:59,305:WARNING:thetaray.common.logging:Encryption is enabled on dataset customer_insights, but data encryption is disabled in deployment\n",
      "2025-07-19 14:17:59,305:WARNING:thetaray.common.logging:Encryption is enabled on dataset transaction, but data encryption is disabled in deployment\n",
      "2025-07-19 14:17:59,305:WARNING:thetaray.common.logging:Encryption is enabled on dataset account, but data encryption is disabled in deployment\n",
      "2025-07-19 14:17:59,305:WARNING:thetaray.common.logging:Encryption is enabled on dataset demo_pay_proc_customer_insights, but data encryption is disabled in deployment\n",
      "2025-07-19 14:17:59,305:WARNING:thetaray.common.logging:Encryption is enabled on dataset demo_ret_indiv_customer_insights, but data encryption is disabled in deployment\n",
      "2025-07-19 14:17:59,711:INFO:thetaray.common.logging:=== Started updating schema ===\n",
      "2025-07-19 14:17:59,916:INFO:thetaray.common.logging:=== Started updating schema on Postgres ===\n",
      "2025-07-19 14:18:11,456:INFO:thetaray.common.logging:found 115 tables in solution public schema\n",
      "2025-07-19 14:18:11,459:INFO:thetaray.common.logging:demo_remittance_ef\n",
      "2025-07-19 14:18:11,466:INFO:thetaray.common.logging:found 115 tables in solution public schema\n",
      "2025-07-19 14:18:11,473:INFO:thetaray.common.logging:demo_ret_smb_ef\n",
      "2025-07-19 14:18:11,480:INFO:thetaray.common.logging:found 115 tables in solution public schema\n",
      "2025-07-19 14:18:11,482:INFO:thetaray.common.logging:party_tr_analysis\n",
      "2025-07-19 14:18:11,488:INFO:thetaray.common.logging:found 115 tables in solution public schema\n",
      "2025-07-19 14:18:11,489:INFO:thetaray.common.logging:tr_analysis\n",
      "2025-07-19 14:18:11,496:INFO:thetaray.common.logging:found 115 tables in solution public schema\n",
      "2025-07-19 14:18:11,498:INFO:thetaray.common.logging:demo_pay_proc_ef\n",
      "2025-07-19 14:18:11,503:INFO:thetaray.common.logging:found 115 tables in solution public schema\n",
      "2025-07-19 14:18:11,504:INFO:thetaray.common.logging:demo_ret_indiv_ef\n",
      "2025-07-19 14:18:11,507:INFO:thetaray.common.logging:=== Finished updating schema ===\n",
      "2025-07-19 14:18:12,652:INFO:thetaray.common.logging:=== Started updating schema for Datasets on Minio ===\n",
      "Setting default log level to \"WARN\".\n",
      "To adjust logging level use sc.setLogLevel(newLevel). For SparkR, use setLogLevel(newLevel).\n",
      "25/07/19 14:18:15 WARN MetricsConfig: Cannot locate configuration: tried hadoop-metrics2-s3a-file-system.properties,hadoop-metrics2.properties\n",
      "Hive Session ID = 58f88b84-dc77-4e52-9eae-8a1cc9823ae3\n",
      "25/07/19 14:18:17 INFO SessionState: Hive Session ID = 58f88b84-dc77-4e52-9eae-8a1cc9823ae3\n",
      "2025-07-19 14:18:21,595:INFO:thetaray.common.logging:### Adding following columns to manager.demo_remittance_transactions metadata: customer_name ###\n",
      "25/07/19 14:18:23 INFO SQLStdHiveAccessController: Created SQLStdHiveAccessController for session context : HiveAuthzSessionContext [sessionString=58f88b84-dc77-4e52-9eae-8a1cc9823ae3, clientType=HIVECLI]\n",
      "2025-07-19 14:18:24,819:INFO:thetaray.common.logging:=== Finished updating schema for Datasets on Minio ===\n",
      "2025-07-19 14:18:24,820:INFO:thetaray.common.logging:=== Started updating schema for Evaluation Flows on Minio ===\n",
      "2025-07-19 14:18:26,760:INFO:thetaray.common.logging:=== Finished updating schema for Evaluation Flows on Minio ===\n"
     ]
    }
   ],
   "source": [
    "from thetaray.api.context import init_context\n",
    "import datetime\n",
    "import yaml\n",
    "\n",
    "import logging\n",
    "logging.basicConfig(level=logging.DEBUG, format='%(message)s')\n",
    "\n",
    "with open('/thetaray/git/solutions/domains/demo_remittance/config/spark_config.yaml') as spark_config_file:\n",
    "    spark_config = yaml.load(spark_config_file, yaml.FullLoader)['spark_config_a']\n",
    "context = init_context(execution_date=datetime.datetime(1970, 2, 1),\n",
    "                       spark_conf=spark_config,\n",
    "                       spark_master='local[*]',\n",
    "                      allow_type_changes=True, \n",
    "                      delete_unused_columns=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "089821e6-a478-49e1-b1db-d1965dcafd88",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-06T12:45:25.256221Z",
     "iopub.status.busy": "2025-05-06T12:45:25.255592Z",
     "iopub.status.idle": "2025-05-06T12:45:25.258312Z",
     "shell.execute_reply": "2025-05-06T12:45:25.257873Z",
     "shell.execute_reply.started": "2025-05-06T12:45:25.256198Z"
    }
   },
   "source": [
    "### Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "6aeaaf18-0599-4319-9d9d-1a3f396ef784",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-07-19T14:18:27.661890Z",
     "iopub.status.busy": "2025-07-19T14:18:27.661166Z",
     "iopub.status.idle": "2025-07-19T14:18:27.666251Z",
     "shell.execute_reply": "2025-07-19T14:18:27.665856Z",
     "shell.execute_reply.started": "2025-07-19T14:18:27.661864Z"
    }
   },
   "outputs": [],
   "source": [
    "from thetaray.api.dataset import dataset_functions\n",
    "\n",
    "from domains.demo_remittance.datasets.customer_monthly import customer_monthly_dataset\n",
    "from domains.demo_remittance.datasets.customers import customers_dataset\n",
    "from domains.demo_remittance.datasets.transactions import transactions_dataset\n",
    "\n",
    "from pyspark.sql import functions as f"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "7bb8500b-fec0-4586-b5b6-02f9983c41ac",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-07-19T14:18:27.667325Z",
     "iopub.status.busy": "2025-07-19T14:18:27.667156Z",
     "iopub.status.idle": "2025-07-19T14:18:28.460642Z",
     "shell.execute_reply": "2025-07-19T14:18:28.460172Z",
     "shell.execute_reply.started": "2025-07-19T14:18:27.667309Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Transacciones generadas: 4002\n",
      "Features agregadas: 120\n",
      "\n",
      "Features del cliente anómalo por mes:\n",
      "    year_month_str  multpl_tx_bl_lim  vel_spike  multi_party_actv  \\\n",
      "119        2025-02                20        204               189   \n",
      "118        2025-03                30        202               197   \n",
      "117        2025-04                29        196               189   \n",
      "116        2025-05                29        170               160   \n",
      "115        2025-06                22        188               180   \n",
      "\n",
      "     hr_jurid_vol  \n",
      "119    4475836.30  \n",
      "118    3401148.71  \n",
      "117    3650333.28  \n",
      "116    3353484.28  \n",
      "115    3936290.24  \n",
      "\n",
      "Transacciones del cliente anómalo: 1152\n",
      "Monto promedio: $20836.55\n",
      "Contrapartes únicas: 1073\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import random, uuid\n",
    "from datetime import datetime\n",
    "from faker import Faker\n",
    "\n",
    "faker = Faker()\n",
    "\n",
    "# ————————————————————————————————————————————————————————————————\n",
    "# Parámetros de referencia\n",
    "# ————————————————————————————————————————————————————————————————\n",
    "HIGH_RISK_COUNTRIES = [\"IR\", \"KP\", \"SY\", \"SD\", \"VE\", \"SO\", \"YE\", \"CU\", \"MM\", \"CF\"]\n",
    "TAX_HEAVEN_COUNTRIES = [\"CY\", \"KY\", \"BS\", \"PA\", \"LU\", \"CH\", \"SG\", \"AE\", \"BM\", \"VG\"]\n",
    "MAX_LIMIT = 10000.0          # límite típico de reporte (CTR / 17b)\n",
    "STRUCTURE_BAND = 500.0       # \"just below\" = dentro de 500 USD bajo el límite\n",
    "VELOCITY_WINDOW = 3          # nº días para el cálculo de spikes\n",
    "\n",
    "ISO_4217 = [\"USD\", \"EUR\", \"GBP\", \"JPY\", \"CAD\", \"MXN\", \"AUD\"]\n",
    "CHANNELS = [\"agent\", \"branch\", \"mobile_app\", \"web\"]\n",
    "STRUCTURE_THRESHOLD = 10000.0\n",
    "\n",
    "def generate_normal_remittance_transactions(customer_id, customer_name, period, n_transactions=30):\n",
    "    \"\"\"\n",
    "    Genera transacciones normales de remesas para clientes regulares\n",
    "    \"\"\"\n",
    "    records = []\n",
    "    customers_pool = [f\"CUST{i:04d}\" for i in range(500, 800)]\n",
    "    \n",
    "    def get_counterparty_details():\n",
    "        cp_name = faker.company()\n",
    "        cp_account = f\"ACC-CPTY-{uuid.uuid4().hex[:12].upper()}\"\n",
    "        cp_contract = f\"CON-{uuid.uuid4().hex[:8].upper()}\"\n",
    "        \n",
    "        # 85% transacciones a países de bajo riesgo\n",
    "        is_high_risk = random.random() < 0.15\n",
    "        if is_high_risk:\n",
    "            cp_country = random.choice(HIGH_RISK_COUNTRIES)\n",
    "            cp_country_risk = 'High'\n",
    "        else:\n",
    "            cp_country = faker.country_code()\n",
    "            while cp_country in HIGH_RISK_COUNTRIES + TAX_HEAVEN_COUNTRIES:\n",
    "                cp_country = faker.country_code()\n",
    "            cp_country_risk = random.choice(['Low', 'Medium'])\n",
    "        \n",
    "        return cp_name, cp_account, cp_contract, cp_country, cp_country_risk\n",
    "\n",
    "    # Generar pool de contrapartes únicas para el mes\n",
    "    num_unique_counterparties = min(n_transactions, random.randint(8, 20))\n",
    "    monthly_counterparties = []\n",
    "    \n",
    "    for _ in range(num_unique_counterparties):\n",
    "        counterparty_id = (\n",
    "            random.choice(customers_pool)\n",
    "            if random.random() < 0.20\n",
    "            else f\"EXT-{uuid.uuid4().hex[:6].upper()}\"\n",
    "        )\n",
    "        cp_name, cp_account, cp_contract, cp_country, cp_risk = get_counterparty_details()\n",
    "        \n",
    "        monthly_counterparties.append({\n",
    "            'id': counterparty_id,\n",
    "            'name': cp_name,\n",
    "            'account': cp_account,\n",
    "            'contract': cp_contract,\n",
    "            'country': cp_country,\n",
    "            'risk': cp_risk\n",
    "        })\n",
    "    \n",
    "    # Generar transacciones distribuidas a lo largo del mes\n",
    "    for _ in range(n_transactions):\n",
    "        ts = period + pd.Timedelta(\n",
    "            days=random.randint(0, 27),\n",
    "            hours=random.randint(0, 23),\n",
    "            minutes=random.randint(0, 59),\n",
    "            seconds=random.randint(0, 59)\n",
    "        )\n",
    "        \n",
    "        # Montos normales para remesas (distribución exponencial)\n",
    "        amt = round(float(np.random.exponential(scale=600)), 2)\n",
    "        amt = max(50, min(amt, 5000))  # Entre 50 y 5000 para transacciones normales\n",
    "        \n",
    "        channel = random.choice(CHANNELS)\n",
    "        in_out = random.choice(['IN', 'OUT'])\n",
    "        \n",
    "        # Seleccionar contraparte del pool mensual\n",
    "        counterparty = random.choice(monthly_counterparties)\n",
    "        \n",
    "        records.append({\n",
    "            'transaction_id': str(uuid.uuid4()),\n",
    "            'customer_id': customer_id,\n",
    "            'customer_name': customer_name,\n",
    "            'counterparty_id': counterparty['id'],\n",
    "            'counterparty_customer_name': counterparty['name'],\n",
    "            'counterparty_account': counterparty['account'],\n",
    "            'counterparty_contract': counterparty['contract'],\n",
    "            'counterparty_country': counterparty['country'],\n",
    "            'counterparty_country_risk': counterparty['risk'],\n",
    "            'transaction_timestamp': ts,\n",
    "            'channel': channel,\n",
    "            'amount': amt,\n",
    "            'currency': 'USD',\n",
    "            'origin_country_code': 'US' if in_out == 'OUT' else counterparty['country'],\n",
    "            'destination_country_code': counterparty['country'] if in_out == 'OUT' else 'US',\n",
    "            'in_out': in_out,\n",
    "        })\n",
    "    \n",
    "    return records\n",
    "\n",
    "def generate_anomalous_remittance_transactions(\n",
    "    customer_name, \n",
    "    months=12,\n",
    "    avg_outgoing_per_month=80,\n",
    "    avg_structuring_per_month=25,\n",
    "    avg_velocity_spike_per_month=15,\n",
    "    avg_multi_party_per_month=25,\n",
    "    avg_high_risk_volume_per_month=30,\n",
    "    pct_counterparty_in_bank=0.20,\n",
    "    start_date=None\n",
    "):\n",
    "    \"\"\"\n",
    "    Genera transacciones anómalas de remesas para el cliente ANOMR001\n",
    "    \"\"\"\n",
    "    if start_date:\n",
    "        today = pd.Timestamp(pd.to_datetime(start_date).replace(day=1, hour=0, minute=0, second=0, microsecond=0))\n",
    "    else:\n",
    "        today = pd.Timestamp(datetime.today().replace(day=1, hour=0, minute=0, second=0, microsecond=0))\n",
    "\n",
    "    periods = [today - pd.DateOffset(months=i) for i in range(months)]\n",
    "    customer_id = \"ANOMR001\"\n",
    "    customers_pool = [f\"CUST{i:04d}\" for i in range(500, 800)]\n",
    "    \n",
    "    records = []\n",
    "\n",
    "    def get_counterparty_details(is_high_risk=False, specified_country=None):\n",
    "        cp_name = faker.company()\n",
    "        cp_account = f\"ACC-CPTY-{uuid.uuid4().hex[:12].upper()}\"\n",
    "        cp_contract = f\"CON-{uuid.uuid4().hex[:8].upper()}\"\n",
    "        \n",
    "        if specified_country:\n",
    "            cp_country = specified_country\n",
    "            cp_country_risk = 'High' if cp_country in HIGH_RISK_COUNTRIES + TAX_HEAVEN_COUNTRIES else random.choice(['Low', 'Medium'])\n",
    "        elif is_high_risk:\n",
    "            cp_country = random.choice(HIGH_RISK_COUNTRIES)\n",
    "            cp_country_risk = 'High'\n",
    "        else:\n",
    "            cp_country = faker.country_code()\n",
    "            while cp_country in HIGH_RISK_COUNTRIES + TAX_HEAVEN_COUNTRIES:\n",
    "                cp_country = faker.country_code()\n",
    "            cp_country_risk = random.choice(['Low', 'Medium'])\n",
    "            \n",
    "        return cp_name, cp_account, cp_contract, cp_country, cp_country_risk\n",
    "\n",
    "    for period in periods:\n",
    "        n_outgoing = np.random.poisson(lam=avg_outgoing_per_month)\n",
    "        n_structuring = np.random.poisson(lam=avg_structuring_per_month)\n",
    "        n_velocity = np.random.poisson(lam=avg_velocity_spike_per_month)\n",
    "        n_multi_party = np.random.poisson(lam=avg_multi_party_per_month)\n",
    "        n_high_risk_volume = np.random.poisson(lam=avg_high_risk_volume_per_month)\n",
    "\n",
    "        # 1) Grandes transferencias a países de alto riesgo\n",
    "        for _ in range(n_outgoing):\n",
    "            ts = period + pd.Timedelta(\n",
    "                days=random.randint(0, 27),\n",
    "                hours=random.randint(0, 23),\n",
    "                minutes=random.randint(0, 59),\n",
    "                seconds=random.randint(0, 59)\n",
    "            )\n",
    "            amt = round(random.uniform(12_000, 25_000), 2)\n",
    "            dest_country = random.choice(HIGH_RISK_COUNTRIES)\n",
    "            \n",
    "            counterparty_id = (\n",
    "                random.choice(customers_pool)\n",
    "                if random.random() < pct_counterparty_in_bank\n",
    "                else f\"EXT-{uuid.uuid4().hex[:6].upper()}\"\n",
    "            )\n",
    "            \n",
    "            cp_name, cp_acc, cp_con, cp_country, cp_risk = get_counterparty_details(is_high_risk=True, specified_country=dest_country)\n",
    "            \n",
    "            records.append({\n",
    "                \"transaction_id\": str(uuid.uuid4()),\n",
    "                \"customer_id\": customer_id,\n",
    "                \"customer_name\": customer_name,\n",
    "                \"counterparty_id\": counterparty_id,\n",
    "                'counterparty_customer_name': cp_name,\n",
    "                'counterparty_account': cp_acc,\n",
    "                'counterparty_contract': cp_con,\n",
    "                'counterparty_country': cp_country,\n",
    "                'counterparty_country_risk': cp_risk,\n",
    "                \"transaction_timestamp\": ts,\n",
    "                \"channel\": random.choice(CHANNELS),\n",
    "                \"amount\": amt,\n",
    "                \"currency\": \"USD\",\n",
    "                \"origin_country_code\": \"US\",\n",
    "                \"destination_country_code\": dest_country,\n",
    "                \"in_out\": \"OUT\"\n",
    "            })\n",
    "\n",
    "        # 2) Structuring: montos justo por debajo del umbral\n",
    "        for _ in range(n_structuring):\n",
    "            ts = period + pd.Timedelta(\n",
    "                days=random.randint(0, 27),\n",
    "                hours=random.randint(0, 23),\n",
    "                minutes=random.randint(0, 59),\n",
    "                seconds=random.randint(0, 59)\n",
    "            )\n",
    "            amt = round(STRUCTURE_THRESHOLD - random.uniform(5, 500), 2)  # Usar STRUCTURE_BAND\n",
    "            dest_country = random.choice([\"MX\", \"PH\", \"CN\", \"IN\"])\n",
    "            \n",
    "            counterparty_id = (\n",
    "                random.choice(customers_pool)\n",
    "                if random.random() < pct_counterparty_in_bank\n",
    "                else f\"EXT-{uuid.uuid4().hex[:6].upper()}\"\n",
    "            )\n",
    "            \n",
    "            cp_name, cp_acc, cp_con, cp_country, cp_risk = get_counterparty_details(specified_country=dest_country)\n",
    "            \n",
    "            records.append({\n",
    "                \"transaction_id\": str(uuid.uuid4()),\n",
    "                \"customer_id\": customer_id,\n",
    "                \"customer_name\": customer_name,\n",
    "                \"counterparty_id\": counterparty_id,\n",
    "                'counterparty_customer_name': cp_name,\n",
    "                'counterparty_account': cp_acc,\n",
    "                'counterparty_contract': cp_con,\n",
    "                'counterparty_country': cp_country,\n",
    "                'counterparty_country_risk': cp_risk,\n",
    "                \"transaction_timestamp\": ts,\n",
    "                \"channel\": \"agent\",\n",
    "                \"amount\": amt,\n",
    "                \"currency\": \"USD\",\n",
    "                \"origin_country_code\": \"US\",\n",
    "                \"destination_country_code\": dest_country,\n",
    "                \"in_out\": \"OUT\"\n",
    "            })\n",
    "\n",
    "        # 3) Velocity spikes: ráfagas de transacciones\n",
    "        if n_velocity > 0:\n",
    "            # Crear varios spikes en el mes\n",
    "            n_spikes = random.randint(1, 3)\n",
    "            for spike_num in range(n_spikes):\n",
    "                spike_start_day = random.randint(0, 27)\n",
    "                spike_start_hour = random.randint(0, 23)\n",
    "                base_ts_spike = period + pd.Timedelta(days=spike_start_day, hours=spike_start_hour)\n",
    "                \n",
    "                spike_size = n_velocity // n_spikes if n_spikes > 0 else n_velocity\n",
    "                \n",
    "                # Usar la misma contraparte para simular velocity spike\n",
    "                counterparty_id = f\"EXT-{uuid.uuid4().hex[:6].upper()}\"\n",
    "                dest_country = random.choice(HIGH_RISK_COUNTRIES)\n",
    "                cp_name, cp_acc, cp_con, cp_country, cp_risk = get_counterparty_details(is_high_risk=True, specified_country=dest_country)\n",
    "                \n",
    "                for i in range(spike_size):\n",
    "                    ts = base_ts_spike + pd.Timedelta(minutes=random.randint(0, 180))  # 3 horas de ventana\n",
    "                    amt = round(random.uniform(2000, 8000), 2)\n",
    "                    \n",
    "                    records.append({\n",
    "                        \"transaction_id\": str(uuid.uuid4()),\n",
    "                        \"customer_id\": customer_id,\n",
    "                        \"customer_name\": customer_name,\n",
    "                        \"counterparty_id\": counterparty_id,\n",
    "                        'counterparty_customer_name': cp_name,\n",
    "                        'counterparty_account': cp_acc,\n",
    "                        'counterparty_contract': cp_con,\n",
    "                        'counterparty_country': cp_country,\n",
    "                        'counterparty_country_risk': cp_risk,\n",
    "                        \"transaction_timestamp\": ts,\n",
    "                        \"channel\": random.choice([\"mobile_app\", \"web\"]),\n",
    "                        \"amount\": amt,\n",
    "                        \"currency\": \"USD\",\n",
    "                        \"origin_country_code\": \"US\",\n",
    "                        \"destination_country_code\": dest_country,\n",
    "                        \"in_out\": \"OUT\"\n",
    "                    })\n",
    "\n",
    "        # 4) Multi-party activity: muchas contrapartes únicas\n",
    "        for _ in range(n_multi_party):\n",
    "            ts = period + pd.Timedelta(\n",
    "                days=random.randint(0, 27),\n",
    "                hours=random.randint(0, 23),\n",
    "                minutes=random.randint(0, 59),\n",
    "                seconds=random.randint(0, 59)\n",
    "            )\n",
    "            amt = round(float(np.random.exponential(scale=600)), 2)\n",
    "            \n",
    "            # Generar contraparte única\n",
    "            counterparty_id = f\"CTR_{uuid.uuid4().hex[:6]}\"\n",
    "            cp_name, cp_acc, cp_con, cp_country, cp_risk = get_counterparty_details()\n",
    "            \n",
    "            records.append({\n",
    "                \"transaction_id\": str(uuid.uuid4()),\n",
    "                \"customer_id\": customer_id,\n",
    "                \"customer_name\": customer_name,\n",
    "                \"counterparty_id\": counterparty_id,\n",
    "                'counterparty_customer_name': cp_name,\n",
    "                'counterparty_account': cp_acc,\n",
    "                'counterparty_contract': cp_con,\n",
    "                'counterparty_country': cp_country,\n",
    "                'counterparty_country_risk': cp_risk,\n",
    "                \"transaction_timestamp\": ts,\n",
    "                \"channel\": random.choice(CHANNELS),\n",
    "                \"amount\": amt,\n",
    "                \"currency\": \"USD\",\n",
    "                \"origin_country_code\": \"US\",\n",
    "                \"destination_country_code\": cp_country,\n",
    "                \"in_out\": \"OUT\"\n",
    "            })\n",
    "\n",
    "        # 5) High-risk volume: grandes montos a países de alto riesgo\n",
    "        for _ in range(n_high_risk_volume):\n",
    "            ts = period + pd.Timedelta(\n",
    "                days=random.randint(0, 27),\n",
    "                hours=random.randint(0, 23),\n",
    "                minutes=random.randint(0, 59),\n",
    "                seconds=random.randint(0, 59)\n",
    "            )\n",
    "            amt = round(random.uniform(50000, 100000), 2)\n",
    "            dest_country = random.choice(HIGH_RISK_COUNTRIES)\n",
    "            \n",
    "            counterparty_id = (\n",
    "                random.choice(customers_pool)\n",
    "                if random.random() < pct_counterparty_in_bank\n",
    "                else f\"EXT-{uuid.uuid4().hex[:6].upper()}\"\n",
    "            )\n",
    "            \n",
    "            cp_name, cp_acc, cp_con, cp_country, cp_risk = get_counterparty_details(is_high_risk=True, specified_country=dest_country)\n",
    "            \n",
    "            records.append({\n",
    "                \"transaction_id\": str(uuid.uuid4()),\n",
    "                \"customer_id\": customer_id,\n",
    "                \"customer_name\": customer_name,\n",
    "                \"counterparty_id\": counterparty_id,\n",
    "                'counterparty_customer_name': cp_name,\n",
    "                'counterparty_account': cp_acc,\n",
    "                'counterparty_contract': cp_con,\n",
    "                'counterparty_country': cp_country,\n",
    "                'counterparty_country_risk': cp_risk,\n",
    "                \"transaction_timestamp\": ts,\n",
    "                \"channel\": random.choice(CHANNELS),\n",
    "                \"amount\": amt,\n",
    "                \"currency\": \"USD\",\n",
    "                \"origin_country_code\": \"US\",\n",
    "                \"destination_country_code\": dest_country,\n",
    "                \"in_out\": \"OUT\"\n",
    "            })\n",
    "\n",
    "        # 6) Transacciones normales adicionales\n",
    "        n_normal = np.random.poisson(lam=20)\n",
    "        for _ in range(n_normal):\n",
    "            ts = period + pd.Timedelta(\n",
    "                days=random.randint(0, 27),\n",
    "                hours=random.randint(0, 23),\n",
    "                minutes=random.randint(0, 59),\n",
    "                seconds=random.randint(0, 59)\n",
    "            )\n",
    "            amt = round(float(np.random.exponential(scale=600)), 2)\n",
    "            \n",
    "            counterparty_id = (\n",
    "                random.choice(customers_pool)\n",
    "                if random.random() < pct_counterparty_in_bank\n",
    "                else f\"EXT-{uuid.uuid4().hex[:6].upper()}\"\n",
    "            )\n",
    "            \n",
    "            cp_name, cp_acc, cp_con, cp_country, cp_risk = get_counterparty_details()\n",
    "            \n",
    "            records.append({\n",
    "                \"transaction_id\": str(uuid.uuid4()),\n",
    "                \"customer_id\": customer_id,\n",
    "                \"customer_name\": customer_name,\n",
    "                \"counterparty_id\": counterparty_id,\n",
    "                'counterparty_customer_name': cp_name,\n",
    "                'counterparty_account': cp_acc,\n",
    "                'counterparty_contract': cp_con,\n",
    "                'counterparty_country': cp_country,\n",
    "                'counterparty_country_risk': cp_risk,\n",
    "                \"transaction_timestamp\": ts,\n",
    "                \"channel\": random.choice(CHANNELS),\n",
    "                \"amount\": amt,\n",
    "                \"currency\": \"USD\",\n",
    "                \"origin_country_code\": \"US\",\n",
    "                \"destination_country_code\": cp_country,\n",
    "                \"in_out\": \"OUT\"\n",
    "            })\n",
    "\n",
    "    return pd.DataFrame(records).sort_values(\"transaction_timestamp\").reset_index(drop=True)\n",
    "\n",
    "def calculate_remittance_aggregated_features(transactions_df, customer_id, customer_name, period):\n",
    "    \"\"\"\n",
    "    Calcula las features agregadas para remesas en un período específico (mensual)\n",
    "    basándose en las transacciones reales generadas\n",
    "    \"\"\"\n",
    "    # Filtrar transacciones del período mensual específico\n",
    "    start_date = period\n",
    "    end_date = period + pd.DateOffset(months=1)\n",
    "    mask = (transactions_df['transaction_timestamp'] >= start_date) & \\\n",
    "           (transactions_df['transaction_timestamp'] < end_date) & \\\n",
    "           (transactions_df['customer_id'] == customer_id)\n",
    "    \n",
    "    period_txs = transactions_df[mask].copy()\n",
    "    \n",
    "    if len(period_txs) == 0:\n",
    "        # Si no hay transacciones, devolver valores por defecto\n",
    "        return {\n",
    "            'customer_id': customer_id,\n",
    "            'customer_name': customer_name,\n",
    "            'year_month': period,\n",
    "            'year_month_str': period.strftime(\"%Y-%m\"),\n",
    "            'multpl_tx_bl_lim': 0,\n",
    "            'vel_spike': 0,\n",
    "            'multi_party_actv': 0,\n",
    "            'hr_jurid_vol': 0.0,\n",
    "            'hr_jurid_vol_pop': 0.0,\n",
    "            'total_tx_amount': 0.0,\n",
    "            'avg_tx_amount': 0.0\n",
    "        }\n",
    "    \n",
    "    amounts = period_txs['amount'].values\n",
    "    timestamps = period_txs['transaction_timestamp']\n",
    "    dest_countries = period_txs['destination_country_code']\n",
    "    counterparties = period_txs['counterparty_id']\n",
    "    \n",
    "    # 1. Multiple transactions below limit (structuring)\n",
    "    below_lim_mask = (amounts >= MAX_LIMIT - STRUCTURE_BAND) & (amounts < MAX_LIMIT)\n",
    "    multiple_tx_below_limit = int(below_lim_mask.sum())\n",
    "    \n",
    "    # 2. Velocity spike - usar rolling window como en el código original\n",
    "    ts_series = pd.Series(1, index=pd.to_datetime(timestamps).sort_values())\n",
    "    rolling_counts = ts_series.rolling(f\"{VELOCITY_WINDOW}D\").sum()\n",
    "    velocity_spike = int((rolling_counts >= 3).sum())\n",
    "    \n",
    "    # 3. Multi-party activity - contrapartes únicas por encima del umbral\n",
    "    unique_counterparties = period_txs['counterparty_id'].nunique()\n",
    "    multi_party_activity = unique_counterparties\n",
    "    \n",
    "    # 4. High-risk jurisdiction volume\n",
    "    hr_mask = dest_countries.isin(HIGH_RISK_COUNTRIES)\n",
    "    high_risk_jurisdiction_volume = float(amounts[hr_mask].sum())\n",
    "    \n",
    "    # 5. High-risk jurisdiction volume with population factor\n",
    "    pop_factor = random.uniform(0.001, 0.006) if customer_id == 'ANOMR001' else random.uniform(0.001, 0.002)\n",
    "    hr_jurid_vol_pop = high_risk_jurisdiction_volume * pop_factor\n",
    "    \n",
    "    # 6. Métricas adicionales\n",
    "    total_tx_amount = float(amounts.sum())\n",
    "    avg_tx_amount = float(amounts.mean())\n",
    "\n",
    "    return {\n",
    "        'customer_id': customer_id,\n",
    "        'customer_name': customer_name,\n",
    "        'year_month': period,\n",
    "        'year_month_str': period.strftime(\"%Y-%m\"),\n",
    "        'multpl_tx_bl_lim': multiple_tx_below_limit,\n",
    "        'vel_spike': velocity_spike,\n",
    "        'multi_party_actv': multi_party_activity,\n",
    "        'hr_jurid_vol': high_risk_jurisdiction_volume,\n",
    "        'hr_jurid_vol_pop': hr_jurid_vol_pop,\n",
    "        'total_tx_amount': total_tx_amount,\n",
    "        'avg_tx_amount': avg_tx_amount\n",
    "    }\n",
    "\n",
    "def generate_remittance_dataset(n_customers=100, months=12, transactions_per_customer_per_month=30):\n",
    "    \"\"\"\n",
    "    Genera el dataset completo de remesas: primero las transacciones, luego las features agregadas\n",
    "    \"\"\"\n",
    "    # Preparar clientes\n",
    "    normal_customers = [f\"CUST{i:04d}\" for i in range(n_customers - 1)]\n",
    "    anomaly_customer = \"ANOMR001\"\n",
    "    all_customers = normal_customers + [anomaly_customer]\n",
    "    \n",
    "    # Generar nombres de clientes\n",
    "    customer_names = {cust: faker.name() for cust in all_customers}\n",
    "    \n",
    "    # Preparar períodos\n",
    "    today = pd.Timestamp(datetime.today().replace(day=1, hour=0, minute=0, second=0, microsecond=0))\n",
    "    periods = [today - pd.DateOffset(months=i) for i in range(months)]\n",
    "    \n",
    "    # 1. Generar todas las transacciones\n",
    "    all_transactions = []\n",
    "    \n",
    "    # Transacciones para clientes normales\n",
    "    for customer in normal_customers:\n",
    "        for period in periods:\n",
    "            txs = generate_normal_remittance_transactions(\n",
    "                customer_id=customer,\n",
    "                customer_name=customer_names[customer],\n",
    "                period=period,\n",
    "                n_transactions=transactions_per_customer_per_month\n",
    "            )\n",
    "            all_transactions.extend(txs)\n",
    "    \n",
    "    # Transacciones para cliente anómalo\n",
    "    anomaly_txs = generate_anomalous_remittance_transactions(\n",
    "        customer_name=customer_names[anomaly_customer],\n",
    "        months=months\n",
    "    )\n",
    "    all_transactions.extend(anomaly_txs.to_dict('records'))\n",
    "    \n",
    "    # Convertir a DataFrame\n",
    "    transactions_df = pd.DataFrame(all_transactions)\n",
    "    \n",
    "    # 2. Calcular features agregadas basándose en las transacciones reales\n",
    "    aggregated_records = []\n",
    "    \n",
    "    for customer in all_customers:\n",
    "        for period in periods:\n",
    "            features = calculate_remittance_aggregated_features(\n",
    "                transactions_df=transactions_df,\n",
    "                customer_id=customer,\n",
    "                customer_name=customer_names[customer],\n",
    "                period=period\n",
    "            )\n",
    "            aggregated_records.append(features)\n",
    "    \n",
    "    aggregated_df = pd.DataFrame(aggregated_records)\n",
    "    \n",
    "    # Ordenar datasets\n",
    "    transactions_df = transactions_df.sort_values(['customer_id', 'transaction_timestamp'])\n",
    "    aggregated_df = aggregated_df.sort_values(['customer_id', 'year_month'])\n",
    "    \n",
    "    return transactions_df, aggregated_df\n",
    "\n",
    "\n",
    "def generate_anomalous_kyc(name: str) -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    Devuelve el registro KYC del cliente anómalo ANOMR001, adaptado a remittances.\n",
    "    \"\"\"\n",
    "    dob = faker.date_of_birth(minimum_age=30, maximum_age=70)\n",
    "    eff_date = faker.date_between(start_date=\"-5y\", end_date=\"-1y\")\n",
    "\n",
    "    data = {\n",
    "        # --- Identificación básica ---\n",
    "        \"customer_id\": \"ANOMR001\",\n",
    "        \"customer_num\": f\"RM-{faker.bothify('######')}\",\n",
    "        \"document_type\": random.choice([\"Passport\", \"National ID\", \"Driver License\"]),\n",
    "        \"document_id\": faker.bothify(\"??########\"),\n",
    "        \"name\": name,\n",
    "        \"date_of_birth\": dob,\n",
    "        \"country_of_birth\": \"CU\",\n",
    "        \"citizenship_countries\": \"United States, Cuba\",\n",
    "\n",
    "        # --- Residencia & contacto ---\n",
    "        \"country_of_residence_code\": \"US\",\n",
    "        \"country_of_residence\": \"United States\",\n",
    "        \"address\": faker.address().replace(\"\\n\", \", \"),\n",
    "        \"phone_number\": faker.phone_number(),\n",
    "        \"email\": faker.email(),\n",
    "\n",
    "        # --- Perfil económico / laboral ---\n",
    "        \"occupation\": random.choice([\"Entrepreneur\", \"Consultant\", \"Investor\"]),\n",
    "        \"primary_source_of_income\": random.choice(\n",
    "            [\"Business income\", \"Investments\", \"Salary\"]),\n",
    "        \"estimated_annual_income_usd\": random.randint(150_000, 500_000),\n",
    "\n",
    "        # --- Clasificación de riesgo AML ---\n",
    "        \"risk_rating\": random.randint(4, 5),       # 4‑5 = alto\n",
    "        \"is_pep\": random.choice([True, False]),\n",
    "        \"is_sanctioned\": False,\n",
    "        \"high_risk_country_exposure\": True,\n",
    "\n",
    "        # --- Límites y frecuencia de remesas ---\n",
    "        \"daily_remittance_limit_usd\": 9_500,       # justo bajo umbral de CTR\n",
    "        \"monthly_remittance_limit_usd\": 50_000,\n",
    "\n",
    "        # --- Metadata ---\n",
    "        \"customer_effective_date\": eff_date,\n",
    "        \"kyc_last_review_date\": datetime.today().date(),\n",
    "        \"segment_type\": \"PERS\",\n",
    "        \"segment_type_description\": \"Personal – Remittance\",\n",
    "        \"sars_flag\": False,\n",
    "    }\n",
    "\n",
    "    return pd.DataFrame([data])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "681a2b4f-d48e-45d2-9e33-e8dd29dda2c0",
   "metadata": {},
   "source": [
    "### Data Gen"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "7f2de590-92ee-496c-9c4f-57cbc6aa0bfa",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-07-19T14:22:32.484782Z",
     "iopub.status.busy": "2025-07-19T14:22:32.484231Z",
     "iopub.status.idle": "2025-07-19T14:22:56.442571Z",
     "shell.execute_reply": "2025-07-19T14:22:56.442020Z",
     "shell.execute_reply.started": "2025-07-19T14:22:32.484749Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-07-19 14:22:40,298:INFO:thetaray.common.logging:### DataSet - writing started ###\n",
      "                                                                                2025-07-19 14:22:44,609:INFO:thetaray.common.logging:### DataSet - writing done, 1200 written, 0 corrupted, 0 rejected  ###\n",
      "                                                                                2025-07-19 14:22:47,175:INFO:thetaray.common.logging:finished publishing records for dataset demo_remittance_customer_monthly\n",
      "2025-07-19 14:22:47,394:INFO:thetaray.common.logging:### DataSet - writing started ###\n",
      "                                                                                2025-07-19 14:22:51,288:INFO:thetaray.common.logging:### DataSet - writing done, 37984 written, 0 corrupted, 0 rejected  ###\n",
      "2025-07-19 14:22:53,514:INFO:thetaray.common.logging:finished publishing records for dataset demo_remittance_transactions\n",
      "2025-07-19 14:22:53,543:INFO:thetaray.common.logging:### DataSet - writing started ###\n",
      "25/07/19 14:22:54 ERROR FileUtils: Failed to delete s3a://thetaray-sonar/warehouse/manager.db/demo_remittance_customers/tr_year=1970/tr_month=2/tr_day=1/tr_date=1970_02_01_00_00_00\n",
      "2025-07-19 14:22:55,864:INFO:thetaray.common.logging:### DataSet - writing done, 1 written, 0 corrupted, 0 rejected  ###\n",
      "2025-07-19 14:22:56,431:INFO:thetaray.common.logging:finished publishing records for dataset demo_remittance_customers\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "transactions_df, agg_df = generate_remittance_dataset()\n",
    "dataset_functions.write(context, context.get_spark_session().createDataFrame(agg_df), customer_monthly_dataset().identifier)\n",
    "dataset_functions.publish(context, customer_monthly_dataset().identifier)\n",
    "anom_name = agg_df.loc[agg_df.customer_id=='ANOMR001']['customer_name'].iloc[0]\n",
    "\n",
    "dataset_functions.write(context, context.get_spark_session().createDataFrame(transactions_df), transactions_dataset().identifier)\n",
    "dataset_functions.publish(context, transactions_dataset().identifier)\n",
    "\n",
    "dataset_functions.write(context, context.get_spark_session().createDataFrame(generate_anomalous_kyc(name=anom_name)), customers_dataset().identifier)\n",
    "dataset_functions.publish(context, customers_dataset().identifier)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a8ff4a06-1fec-4f21-a60d-b758a671794b",
   "metadata": {},
   "outputs": [],
   "source": [
    "context.close()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.20"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
