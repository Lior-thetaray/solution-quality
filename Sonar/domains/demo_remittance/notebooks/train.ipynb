{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "3e23daba-fbdc-40f0-aea9-829771491c47",
   "metadata": {},
   "source": [
    "### Init Context"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "077e9e4b-1624-4709-bb34-e51873f83139",
   "metadata": {},
   "outputs": [],
   "source": [
    "from thetaray.api.context import init_context\n",
    "import datetime\n",
    "import yaml\n",
    "\n",
    "import logging\n",
    "logging.basicConfig(level=logging.DEBUG, format='%(message)s')\n",
    "\n",
    "with open('/thetaray/git/solutions/domains/demo_remittance/config/spark_config.yaml') as spark_config_file:\n",
    "    spark_config = yaml.load(spark_config_file, yaml.FullLoader)['spark_config_a']\n",
    "context = init_context(execution_date=datetime.datetime(1970, 1, 1),\n",
    "                       spark_conf=spark_config,\n",
    "                       spark_master='local[*]')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b582f516-abd7-4452-b16a-11afba4519ef",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-06T12:03:39.026382Z",
     "iopub.status.busy": "2025-05-06T12:03:39.025702Z",
     "iopub.status.idle": "2025-05-06T12:03:39.028658Z",
     "shell.execute_reply": "2025-05-06T12:03:39.028210Z",
     "shell.execute_reply.started": "2025-05-06T12:03:39.026354Z"
    }
   },
   "source": [
    "### Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8557a35f-98d9-40b6-a4aa-0a29e7004bde",
   "metadata": {},
   "outputs": [],
   "source": [
    "from thetaray.api.dataset import dataset_functions\n",
    "from thetaray.api.evaluation import fit_on_worker\n",
    "from thetaray.api.histograms import save_histograms\n",
    "from thetaray.api.evaluation.preprocess.features_extractor import FeaturesExtractor\n",
    "from thetaray.api.models import save_model\n",
    "from thetaray.api.anomaly_detection import ThetaRayDetector\n",
    "from thetaray.api.evaluation.preprocess.numeric_features import NumericFeaturesTransformer\n",
    "\n",
    "import mlflow\n",
    "from pyspark.sql import functions as f\n",
    "\n",
    "from domains.demo_remittance.datasets.customer_monthly import customer_monthly_dataset as input_dataset\n",
    "from domains.demo_remittance.evaluation_flows.ef import evaluation_flow as ef"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fbbe7752-e7bf-423e-8245-175a2ce56fe6",
   "metadata": {},
   "source": [
    "### Load data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1517c5fd-e3bc-4d09-b073-2d474502d8c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = dataset_functions.read(context, input_dataset().identifier)\n",
    "data = data.orderBy([f.hash('customer_id'), 'year_month']).limit(1000000)\n",
    "data_pd = data.toPandas()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6a9b5fbb-65e5-4f43-9d60-79417b116ad9",
   "metadata": {},
   "source": [
    "### Model Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "314e0252-2ade-4816-9d98-059738f1d201",
   "metadata": {},
   "outputs": [],
   "source": [
    "requested_features = ['multpl_tx_bl_lim', \n",
    "                      'vel_spike', \n",
    "                      'multi_party_actv', \n",
    "                      'hr_jurid_vol',\n",
    "                     'total_tx_amount',\n",
    "                     'avg_tx_amount']\n",
    "nft = NumericFeaturesTransformer(features=requested_features, strategy='constant', fill_value=0.0)\n",
    "fu = FeaturesExtractor([nft])\n",
    "trd = ThetaRayDetector(algo_type=['Ny', 'RL', 'NF'],\n",
    "                       learning_method=1,\n",
    "                       normalization_type=1,\n",
    "                       Fusion_threshold=0.3,\n",
    "                       Rating_percentile=5.0,\n",
    "                       set_zero_rating=1)\n",
    "\n",
    "with mlflow.start_run(nested=True):\n",
    "    feature_extraction_model = fit_on_worker(fu.fit, X=data_pd)\n",
    "    save_model(ef().evaluation_steps[0].feature_extraction_model.name, feature_extraction_model, tags=ef().evaluation_steps[0].feature_extraction_model.tags)\n",
    "    detection_model = fit_on_worker(trd.fit, X=feature_extraction_model.transform(data_pd))\n",
    "    save_model(ef().evaluation_steps[0].detection_model.name, detection_model, tags=ef().evaluation_steps[0].detection_model.tags)\n",
    "    save_histograms(context, data_pd, requested_features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "82828789-d28d-40f7-8b7c-1f4ab29b87a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "context.close()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.20"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
